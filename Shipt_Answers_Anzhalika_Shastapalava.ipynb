{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = pd.read_csv(\"/Users/angelika/Desktop/Shipt-DataAnalyst-TakeHome/InterviewData_Cost.csv\")\n",
    "rev = pd.read_csv(\"/Users/angelika/Desktop/Shipt-DataAnalyst-TakeHome/InterviewData_Rev.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question1 \n",
    "Using any functions/packages you want,join these two data sets by “date” and “source_id”,returning all rows from both regardless of whether there is a match between the two data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date          0\n",
       "source_id     0\n",
       "revenue      79\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source_id</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/17/14</td>\n",
       "      <td>PA0577</td>\n",
       "      <td>7168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/17/14</td>\n",
       "      <td>PA0354</td>\n",
       "      <td>7615.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/7/14</td>\n",
       "      <td>PA0607</td>\n",
       "      <td>4054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/25/14</td>\n",
       "      <td>PA0745</td>\n",
       "      <td>9317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/30/14</td>\n",
       "      <td>PA0923</td>\n",
       "      <td>5586.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date source_id    cost\n",
       "0  10/17/14    PA0577  7168.0\n",
       "1   8/17/14    PA0354  7615.0\n",
       "2    1/7/14    PA0607  4054.0\n",
       "3   8/25/14    PA0745  9317.0\n",
       "4  11/30/14    PA0923  5586.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to use outer join in order to preserve value from both datasets regardless of their occurances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = pd.merge(cost, rev,  how = \"outer\", left_on = [\"source_id\",\"date\"], right_on=[\"source_id\",\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source_id</th>\n",
       "      <th>cost</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/17/14</td>\n",
       "      <td>PA0577</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>8417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/17/14</td>\n",
       "      <td>PA0354</td>\n",
       "      <td>7615.0</td>\n",
       "      <td>4200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/7/14</td>\n",
       "      <td>PA0607</td>\n",
       "      <td>4054.0</td>\n",
       "      <td>7935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/25/14</td>\n",
       "      <td>PA0745</td>\n",
       "      <td>9317.0</td>\n",
       "      <td>5536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/30/14</td>\n",
       "      <td>PA0923</td>\n",
       "      <td>5586.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date source_id    cost  revenue\n",
       "0  10/17/14    PA0577  7168.0   8417.0\n",
       "1   8/17/14    PA0354  7615.0   4200.0\n",
       "2    1/7/14    PA0607  4054.0   7935.0\n",
       "3   8/25/14    PA0745  9317.0   5536.0\n",
       "4  11/30/14    PA0923  5586.0      NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source_id</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/1/14</td>\n",
       "      <td>PA0368</td>\n",
       "      <td>5717.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date source_id  revenue\n",
       "0  8/1/14    PA0368   5717.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev.loc[(rev.source_id==\"PA0368\") & (rev.date ==\"8/1/14\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source_id</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, source_id, cost]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost.loc[(cost.source_id==\"PA0368\") & (rev.date ==\"8/1/14\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source_id</th>\n",
       "      <th>cost</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>8/1/14</td>\n",
       "      <td>PA0368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5717.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date source_id  cost  revenue\n",
       "10000  8/1/14    PA0368   NaN   5717.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join.loc[(df_join.source_id==\"PA0368\") & (df_join.date ==\"8/1/14\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see now we have both cost and revenue in one table. NaN value signal that there were no accurace for that specific date and id in one of the data sets. As illustrated with source_id==\"PA0368\"date ==\"8/1/14\" from example above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data verification for question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      "date         10000 non-null object\n",
      "source_id    10000 non-null object\n",
      "revenue      9921 non-null float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "rev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      "date         10000 non-null object\n",
      "source_id    10000 non-null object\n",
      "cost         9900 non-null float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "cost.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are 9921 non null records for revenue and 9900 for cost. Let' make sure that all of them were preserved in our merged dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14618 entries, 0 to 14617\n",
      "Data columns (total 4 columns):\n",
      "date         14618 non-null object\n",
      "source_id    14618 non-null object\n",
      "cost         9900 non-null float64\n",
      "revenue      9921 non-null float64\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 571.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_join.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we have merged dataset for both revenue and cost with all records preserved even without occurances in both of original datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question2\n",
    "Using any functions/packages you want,join these two datasets by “date” and “source_id”,returning only the rows from the “Cost” file that have no corresponding date in the “Revenue” file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cost_only = df_join.loc[(df_join.revenue.isnull()==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source_id</th>\n",
       "      <th>cost</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/30/14</td>\n",
       "      <td>PA0923</td>\n",
       "      <td>5586.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12/17/14</td>\n",
       "      <td>PA0952</td>\n",
       "      <td>6662.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5/22/14</td>\n",
       "      <td>PA0411</td>\n",
       "      <td>4795.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10/14/14</td>\n",
       "      <td>PA0168</td>\n",
       "      <td>9651.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2/13/14</td>\n",
       "      <td>PA0354</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date source_id    cost  revenue\n",
       "4   11/30/14    PA0923  5586.0      NaN\n",
       "6   12/17/14    PA0952  6662.0      NaN\n",
       "7    5/22/14    PA0411  4795.0      NaN\n",
       "9   10/14/14    PA0168  9651.0      NaN\n",
       "10   2/13/14    PA0354  2752.0      NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_cost_only.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question3\n",
    "Using your result from #1,what are the Top 4 sources(“source_id” values)in terms of total revenue generation across this data set? How would you visualize the monthly revenue for those Top 4 sources? (note: you don’t need to actually create a plot; you can just describe what your ideal visual would look like)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to answer this question I need to group by values by id and sum up revenue values for each id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "top4 = df_join.groupby([\"source_id\"]).sum().sort_values(\"revenue\", ascending=False).head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PA0527</th>\n",
       "      <td>1023620.0</td>\n",
       "      <td>1385747.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA0308</th>\n",
       "      <td>894082.0</td>\n",
       "      <td>1338615.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA0352</th>\n",
       "      <td>974021.0</td>\n",
       "      <td>1309685.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA0552</th>\n",
       "      <td>868176.0</td>\n",
       "      <td>1283190.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cost    revenue\n",
       "source_id                      \n",
       "PA0527     1023620.0  1385747.0\n",
       "PA0308      894082.0  1338615.0\n",
       "PA0352      974021.0  1309685.0\n",
       "PA0552      868176.0  1283190.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would visualize it as a histogram, in order to better illustarte revenue levels acroos different ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEnCAYAAABsR64CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAG6NJREFUeJzt3X+QZWV95/H3ZxlB1PB7NIRhM0RnTRCzUWaRxPxQxsBAXIfKSoRswqhUTYXCbDZmN0KSComGLGyyISGluCgTBk1EQkyYNZhxFjUmFUUGUAYEpBcVOiAMDhAjMYh+94/7tF6a290zfa4cbs/7VdXV537Pc87z9FPd85nz695UFZIkdfFv+h6AJGnyGSaSpM4ME0lSZ4aJJKkzw0SS1JlhIknqzDCRJHVmmEiSOjNMJEmdLet7AE+VQw45pFauXNn3MCRpotxwww0PVtXyhdrtMWGycuVKtm3b1vcwJGmiJPnirrTzNJckqTPDRJLUmWEiSepswTBJsjHJA0luGbHuvyWpJIe010lyUZKpJDcneelQ2/VJ7mxf64fqRyfZ3ra5KEla/aAkW1v7rUkOXKgPSVI/duXI5DJg7exiksOBnwTuHiqfCKxqXxuAi1vbg4BzgZcBxwDnzoRDa7NhaLuZvs4Grq2qVcC17fWcfUiS+rNgmFTVx4GdI1ZdCPwqMPzpWuuAy2vgk8ABSQ4FTgC2VtXOqnoI2Aqsbev2q6pP1OBTui4HTh7a16a2vGlWfVQfkqSeLOqaSZLXAP9YVZ+Zteow4J6h19OtNl99ekQd4HlVdR9A+/7cBfoYNc4NSbYl2bZjx45d/OkkSbtrt8MkybOAXwd+c9TqEbVaRH3eIezqNlV1SVWtrqrVy5cv+MyNJGmRFnNk8nzgCOAzSb4ArABuTPLdDI4SDh9quwK4d4H6ihF1gPtnTl+17w+0+lz7kiT1ZLefgK+q7Xz7lBMtUFZX1YNJNgNvSnIFg4vtj1TVfUm2AL87dNH9eOCcqtqZ5CtJjgWuA04H/ri12QysB85v368eqj+pj939OcZh5dl/3Ue3u+0L5/9U30OQtMQtGCZJ3ge8AjgkyTRwblVdOkfza4CTgCngUeANAC003gZc39q9tapmLuqfyeCOsX2BD7UvGITIlUnOYHDH2Cnz9SFJ6s+CYVJVpy2wfuXQcgFnzdFuI7BxRH0bcNSI+peBNSPqc/YhSeqHT8BLkjozTCRJnRkmkqTODBNJUmd7zIdjaQL81v59j2DX/NYjfY9AetrxyESS1JlhIknqzDCRJHXmNRNpiXrxphf3PYQFbV+/ve8haEw8MpEkdWaYSJI6M0wkSZ15zUSSFnDb9/9A30PYJT9w+2299e2RiSSpM8NEktSZYSJJ6swwkSR1ZphIkjozTCRJnRkmkqTODBNJUmcLhkmSjUkeSHLLUO33ktye5OYkf5nkgKF15ySZSnJHkhOG6mtbbSrJ2UP1I5Jcl+TOJO9Psner79NeT7X1KxfqQ5LUj105MrkMWDurthU4qqp+EPgccA5AkiOBU4EXtW3ekWSvJHsBbwdOBI4ETmttAS4ALqyqVcBDwBmtfgbwUFW9ALiwtZuzj938uSVJY7RgmFTVx4Gds2ofrqrH28tPAiva8jrgiqr616r6PDAFHNO+pqrqrqp6DLgCWJckwHHAVW37TcDJQ/va1JavAta09nP1IUnqyTiumbwR+FBbPgy4Z2jddKvNVT8YeHgomGbqT9hXW/9Iaz/Xvp4kyYYk25Js27Fjx6J+OEnSwjqFSZJfBx4H/nSmNKJZLaK+mH09uVh1SVWtrqrVy5cvH9VEkjQGi37X4CTrgVcDa6pq5h/zaeDwoWYrgHvb8qj6g8ABSZa1o4/h9jP7mk6yDNifwem2+fqQJPVgUUcmSdYCbwFeU1WPDq3aDJza7sQ6AlgFfAq4HljV7tzam8EF9M0thD4KvLZtvx64emhf69vya4GPtPZz9SFJ6smCRyZJ3ge8AjgkyTRwLoO7t/YBtg6uifPJqvqFqro1yZXAZxmc/jqrqr7R9vMmYAuwF7Cxqm5tXbwFuCLJ7wA3AZe2+qXAe5JMMTgiORVgvj4kSf1YMEyq6rQR5UtH1GbanwecN6J+DXDNiPpdjLgbq6q+BpyyO31IkvrhE/CSpM4ME0lSZ4aJJKkzw0SS1JlhIknqzDCRJHVmmEiSOjNMJEmdGSaSpM4ME0lSZ4aJJKkzw0SS1JlhIknqzDCRJHVmmEiSOjNMJEmdGSaSpM4ME0lSZ4aJJKkzw0SS1JlhIknqbMEwSbIxyQNJbhmqHZRka5I72/cDWz1JLkoyleTmJC8d2mZ9a39nkvVD9aOTbG/bXJQki+1DktSPXTkyuQxYO6t2NnBtVa0Crm2vAU4EVrWvDcDFMAgG4FzgZcAxwLkz4dDabBjabu1i+pAk9WfBMKmqjwM7Z5XXAZva8ibg5KH65TXwSeCAJIcCJwBbq2pnVT0EbAXWtnX7VdUnqqqAy2fta3f6kCT1ZLHXTJ5XVfcBtO/PbfXDgHuG2k232nz16RH1xfTxJEk2JNmWZNuOHTt26weUJO26cV+Az4haLaK+mD6eXKy6pKpWV9Xq5cuXL7BbSdJiLTZM7p85tdS+P9Dq08DhQ+1WAPcuUF8xor6YPiRJPVlsmGwGZu7IWg9cPVQ/vd1xdSzwSDtFtQU4PsmB7cL78cCWtu4rSY5td3GdPmtfu9OHJKknyxZqkOR9wCuAQ5JMM7gr63zgyiRnAHcDp7Tm1wAnAVPAo8AbAKpqZ5K3Ade3dm+tqpmL+mcyuGNsX+BD7Yvd7UOS1J8Fw6SqTptj1ZoRbQs4a479bAQ2jqhvA44aUf/y7vYhSeqHT8BLkjozTCRJnRkmkqTODBNJUmeGiSSpM8NEktSZYSJJ6swwkSR1ZphIkjozTCRJnRkmkqTODBNJUmeGiSSpM8NEktSZYSJJ6swwkSR1ZphIkjozTCRJnRkmkqTODBNJUmeGiSSps05hkuSXk9ya5JYk70vyzCRHJLkuyZ1J3p9k79Z2n/Z6qq1fObSfc1r9jiQnDNXXttpUkrOH6iP7kCT1Y9FhkuQw4L8Aq6vqKGAv4FTgAuDCqloFPASc0TY5A3ioql4AXNjakeTItt2LgLXAO5LslWQv4O3AicCRwGmtLfP0IUnqQdfTXMuAfZMsA54F3AccB1zV1m8CTm7L69pr2vo1SdLqV1TVv1bV54Ep4Jj2NVVVd1XVY8AVwLq2zVx9SJJ6sOgwqap/BH4fuJtBiDwC3AA8XFWPt2bTwGFt+TDgnrbt4639wcP1WdvMVT94nj6eIMmGJNuSbNuxY8dif1RJ0gK6nOY6kMFRxRHA9wDPZnBKaraa2WSOdeOqP7lYdUlVra6q1cuXLx/VRJI0Bl1Oc70K+HxV7aiqrwMfAH4EOKCd9gJYAdzblqeBwwHa+v2BncP1WdvMVX9wnj4kST3oEiZ3A8cmeVa7jrEG+CzwUeC1rc164Oq2vLm9pq3/SFVVq5/a7vY6AlgFfAq4HljV7tzam8FF+s1tm7n6kCT1oMs1k+sYXAS/Edje9nUJ8BbgzUmmGFzfuLRtcilwcKu/GTi77edW4EoGQfQ3wFlV9Y12TeRNwBbgNuDK1pZ5+pAk9WDZwk3mVlXnAufOKt/F4E6s2W2/Bpwyx37OA84bUb8GuGZEfWQfkqR++AS8JKkzw0SS1JlhIknqzDCRJHVmmEiSOjNMJEmdGSaSpM4ME0lSZ4aJJKkzw0SS1JlhIknqzDCRJHVmmEiSOjNMJEmdGSaSpM4ME0lSZ4aJJKkzw0SS1JlhIknqzDCRJHXWKUySHJDkqiS3J7ktyQ8nOSjJ1iR3tu8HtrZJclGSqSQ3J3np0H7Wt/Z3Jlk/VD86yfa2zUVJ0uoj+5Ak9aPrkckfAX9TVd8P/HvgNuBs4NqqWgVc214DnAisal8bgIthEAzAucDLgGOAc4fC4eLWdma7ta0+Vx+SpB4sOkyS7Af8OHApQFU9VlUPA+uATa3ZJuDktrwOuLwGPgkckORQ4ARga1XtrKqHgK3A2rZuv6r6RFUVcPmsfY3qQ5LUgy5HJt8H7AD+JMlNSd6d5NnA86rqPoD2/bmt/WHAPUPbT7fafPXpEXXm6UOS1IMuYbIMeClwcVW9BPgq859uyohaLaK+y5JsSLItybYdO3bszqaSpN3QJUymgemquq69vopBuNzfTlHRvj8w1P7woe1XAPcuUF8xos48fTxBVV1SVauravXy5csX9UNKkha26DCpqi8B9yR5YSutAT4LbAZm7shaD1zdljcDp7e7uo4FHmmnqLYAxyc5sF14Px7Y0tZ9Jcmx7S6u02fta1QfkqQeLOu4/S8Cf5pkb+Au4A0MAurKJGcAdwOntLbXACcBU8CjrS1VtTPJ24DrW7u3VtXOtnwmcBmwL/Ch9gVw/hx9SJJ60ClMqurTwOoRq9aMaFvAWXPsZyOwcUR9G3DUiPqXR/UhSeqHT8BLkjozTCRJnRkmkqTODBNJUmeGiSSpM8NEktSZYSJJ6swwkSR1ZphIkjozTCRJnRkmkqTODBNJUmeGiSSpM8NEktSZYSJJ6swwkSR1ZphIkjozTCRJnRkmkqTODBNJUmeGiSSps85hkmSvJDcl+WB7fUSS65LcmeT9SfZu9X3a66m2fuXQPs5p9TuSnDBUX9tqU0nOHqqP7EOS1I9xHJn8EnDb0OsLgAurahXwEHBGq58BPFRVLwAubO1IciRwKvAiYC3wjhZQewFvB04EjgROa23n60OS1INOYZJkBfBTwLvb6wDHAVe1JpuAk9vyuvaatn5Na78OuKKq/rWqPg9MAce0r6mququqHgOuANYt0IckqQddj0z+EPhV4Jvt9cHAw1X1eHs9DRzWlg8D7gFo6x9p7b9Vn7XNXPX5+pAk9WDRYZLk1cADVXXDcHlE01pg3bjqo8a4Icm2JNt27NgxqokkaQy6HJm8HHhNki8wOAV1HIMjlQOSLGttVgD3tuVp4HCAtn5/YOdwfdY2c9UfnKePJ6iqS6pqdVWtXr58+eJ/UknSvBYdJlV1TlWtqKqVDC6gf6Sq/jPwUeC1rdl64Oq2vLm9pq3/SFVVq5/a7vY6AlgFfAq4HljV7tzau/WxuW0zVx+SpB58J54zeQvw5iRTDK5vXNrqlwIHt/qbgbMBqupW4Ergs8DfAGdV1TfaNZE3AVsY3C12ZWs7Xx+SpB4sW7jJwqrqY8DH2vJdDO7Emt3ma8Apc2x/HnDeiPo1wDUj6iP7kCT1wyfgJUmdGSaSpM4ME0lSZ4aJJKkzw0SS1JlhIknqzDCRJHVmmEiSOjNMJEmdGSaSpM4ME0lSZ4aJJKkzw0SS1JlhIknqzDCRJHVmmEiSOjNMJEmdGSaSpM4ME0lSZ4aJJKkzw0SS1NmiwyTJ4Uk+muS2JLcm+aVWPyjJ1iR3tu8HtnqSXJRkKsnNSV46tK/1rf2dSdYP1Y9Osr1tc1GSzNeHJKkfXY5MHgd+pap+ADgWOCvJkcDZwLVVtQq4tr0GOBFY1b42ABfDIBiAc4GXAccA5w6Fw8Wt7cx2a1t9rj4kST1YdJhU1X1VdWNb/gpwG3AYsA7Y1JptAk5uy+uAy2vgk8ABSQ4FTgC2VtXOqnoI2Aqsbev2q6pPVFUBl8/a16g+JEk9GMs1kyQrgZcA1wHPq6r7YBA4wHNbs8OAe4Y2m261+erTI+rM04ckqQedwyTJc4C/AP5rVf3TfE1H1GoR9d0Z24Yk25Js27Fjx+5sKknaDZ3CJMkzGATJn1bVB1r5/naKivb9gVafBg4f2nwFcO8C9RUj6vP18QRVdUlVra6q1cuXL1/cDylJWlCXu7kCXArcVlV/MLRqMzBzR9Z64Oqh+untrq5jgUfaKaotwPFJDmwX3o8HtrR1X0lybOvr9Fn7GtWHJKkHyzps+3Lg54HtST7dar8GnA9cmeQM4G7glLbuGuAkYAp4FHgDQFXtTPI24PrW7q1VtbMtnwlcBuwLfKh9MU8fkqQeLDpMqurvGX1dA2DNiPYFnDXHvjYCG0fUtwFHjah/eVQfkqR++AS8JKkzw0SS1JlhIknqzDCRJHVmmEiSOjNMJEmdGSaSpM4ME0lSZ4aJJKkzw0SS1JlhIknqzDCRJHVmmEiSOjNMJEmdGSaSpM4ME0lSZ4aJJKkzw0SS1JlhIknqzDCRJHVmmEiSOpvoMEmyNskdSaaSnN33eCRpTzWxYZJkL+DtwInAkcBpSY7sd1SStGea2DABjgGmququqnoMuAJY1/OYJGmPNMlhchhwz9Dr6VaTJD3FlvU9gA4yolZPaJBsADa0l/+c5I7v+Ki6OwR4cJw7zAXj3NvEGft88tujfvX2COP/3Xz9HjuX8J343cx3ZD6/d1caTXKYTAOHD71eAdw73KCqLgEueSoH1VWSbVW1uu9xLBXO5/g4l+O11OZzkk9zXQ+sSnJEkr2BU4HNPY9JkvZIE3tkUlWPJ3kTsAXYC9hYVbf2PCxJ2iNNbJgAVNU1wDV9j2PMJuq03ARwPsfHuRyvJTWfqaqFW0mSNI9JvmYiSXqaMEwkSZ0ZJpKkzgyTHiV5TZJn9j2OpSTJsqHl5yRZneSgPsc0yZI8Y0TtkD7GMumS7Jfk+SPqP9jHeMbNMOnX+4HpJO9JclJ780otUpLXA/cn+VySE4GbgQuAzyQ5rdfBTZgkr0wyDdyb5MNJVg6t/nA/o5pcSX4GuB34iyS3JvkPQ6sv62dU42WY9Ot2YBXwceBXGPzhvjPJT/Q7rIn1K8ALgRMYBPVPVtUaYDVwTp8Dm0D/EzihqpYzuIV1a5Jj27o9+j1QFunXgKOr6oeANwDvSfLTbd2SmM+Jfs5kCaiqegh4F/CuJN8N/AxwfpIVVXX4/Jtrlm9U1YPAg0n+uar+H0BV3Z/vzHsWLWV7zzwEXFVXJbkN+ED73CCfJ9h9e1XVfQBV9akkrwQ+mGQFS2Q+fc6kR0luqqqXzLHue6vqi0/1mCZZks3ArcB3MfiMm5uADwCvAn6kqk7ocXgTJck24NVV9aWh2grgg8Dzq+q7ehvcBEryD8DPz/wHp9W+C/gr4Eerap/eBjcmnubq1y/PtcIgWZSfA/6JwZuAvgb4BIPTW88DXt/fsCbS2Qzm7Vuqahp4BXB+HwOacGcy63RWVX0FWAu8sZcRjZlHJpKkzjwy6VGSw5NckeTvkvza8G2YSf6qz7FNoiT7Jzk/ye1Jdib5cpLbWu2Avsc3SZKsHVreP8mlSW5O8mdJnjfftnqyJG8cWl6R5NokDyf5hyT/rs+xjYth0q+NwMeAXwQOBf42ycFt3S59II2e4ErgIeAVVXVQVR0MvBJ4GPjzXkc2eX53aPl/AfcB/5HBRz/8715GNNneNLT8Bwx+Vw8Cfg+4uJcRjZmnuXqU5NPtVsGZ1z/H4Bz/a4A/r6qX9ja4CZTkjqp64e6u05MluXHm92/E7+kTXmthC8znnDfiTBJvDe7XM5I8s6q+BlBV703yJQaf0fLsfoc2kb6Y5FeBTVV1P0A7JfN64J4+BzaBnpvkzQwuGu+XJPXt/3l6RmP3rUhyEYP5XJ7kGVX19bbuSe8yMIn8pejXu4GXDReq6v8CpwC39DKiyfY64GAGpwt3JtnJ4DTiQQye39GuexeDW6yfA2xi8HnltGehPt3juCbVfwduALYxeIDxOfCt+VwSnxDraS5JUmee5upRkkPaE9szr38OOIbBUcm7yqTfLRk85n4KgyeKrwKOA9YxeNuad1bVN3sc3kRxLsdrT/hb98ikR7Muyv0G8GPAnwGvBqaras6HGvVkSd4BPBfYm8HDi/sA/wc4Cbi/qn6px+FNFOdyvPaEv3XDpEfDd3EkuRH4sar6anve5MaqenG/I5wsSbZX1Yvb/H0JOLSqHmtvS3+T87nrnMvx2hP+1j3N1a99k7yEwY0Qe1XVVwGq6utJvtHv0CbS4/Ct+bu+qh5rrx93PnebczleS/5v3TDp130MHmAC2Jnk0Kq6rz24+HiP45pUX0rynKr656oafoL7u4HHehzXJHIux2vJ/617mutpqH1I1j5V9WjfY1kKkjwbeHZVPdD3WCadczleS+lv3TDpWZL9Gbxz6GEM7py5F9hSVQ/3OrAJ5XyOj3M5Xkt9Pn1osUdJTgduZPC23s9i8NT7K4Eb2jrtBudzfJzL8doT5tMjkx4luQN42ez/mSQ5ELiuqpbEu4k+VZzP8XEux2tPmE+PTPoVRn9k5zdZIp8L/RRzPsfHuRyvJT+f3s3Vr/OAG5N8mG+/EeG/BX4S+J3eRjW5nM/xcS7Ha8nPp6e5etYOc09gcFEuDD5ydktVPdTrwCaU8zk+zuV4LfX5NEyehpK8HPjZqjqr77EsBc7n+DiX47WU5tPTXE8TSX4I+FkGb5X+eeAD/Y5osjmf4+NcjtdSnU/DpEfts59PBU4Dvgy8n8HR4it7HdiEcj7Hx7kcrz1hPj3N1aMk3wT+DjijqqZa7a6q+r5+RzaZnM/xcS7Ha0+YT28N7td/YvCOrB9N8q4ka1gitwn2xPkcH+dyvJb8fHpk8jTQ3u/oZAaHwMcx+JjUv6yqD/c6sAnlfI6PczleS3k+DZOnmSQHMfiEu9dV1XF9j2fSOZ/j41yO11KbT8OkR0meCfwC8AJgO3BpVS2Jt6Pug/M5Ps7leO0J82mY9CjJ+4GvM7gwdyLwRT8OdfGcz/FxLsdrT5hPw6RHMx+N2paXAZ+a+Zxo7T7nc3ycy/HaE+bTu7n69fWZhaV2yNsT53N8nMvxWvLz6ZFJj9pnP3915iWwL/BoW66q2q+vsU0i53N8nMvx2hPm0zCRJHXmaS5JUmeGiSSpM8NEktSZYSJNsCRvTfKqEfVXJPlgH2PSnsm3oJd6kGTZOG4RrarfHMd4pK48MpF2QZJnJ/nrJJ9JckuS1yVZk+SmJNuTbEyyT2v7hSSHtOXVST7Wln8rySXtc8AvT7JXkt9v29+c5Bdbu6OT/G2SG5JsSXLoPOO6LMlr2/LaJLcn+Xvgp7/DUyI9gUcm0q5ZC9xbVT8FkGR/4BZgTVV9LsnlwJnAHy6wn6OBH62qf0lyJnAE8JKqejzJQUmeAfwxsK6qdiR5HXAe8Mb5dtre++ldDN6JdorBhy9JTxmPTKRdsx14VZILkvwYsBL4fFV9rq3fBPz4Luxnc1X9S1t+FfDOmdNdVbUTeCFwFLA1yaeB3wBW7MJ+v7+N584aPDz23l38uaSx8MhE2gXt6ONo4CTgfwDzff7E43z7P2rPnLXuq0PLAWY/NRzg1qr64cUMcxHbSGPhkYm0C5J8D/BoVb0X+H3gR4CVSV7Qmvw88Ldt+QsMTmfB4BP25vJh4BfaG//NfL7FHcDyJD/cas9I8qJdGOLtwBFJnt9en7ZLP5g0JoaJtGteDHyqnXr6dQann94A/HmS7cA3gXe2tr8N/FGSvwO+Mc8+3w3cDdyc5DPAz1bVY8BrgQta7dMMgmteVfU1YAPw1+0C/BcX8TNKi+Z7c0mSOvPIRJLUmRfgpQmQ5O3Ay2eV/6iq/qSP8UizeZpLktSZp7kkSZ0ZJpKkzgwTSVJnhokkqTPDRJLU2f8HIzJ20OhyHJEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top4.revenue.plot.bar()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question4\n",
    "Assuming you’ve read the data in to a Pandas Data Frame called df,run the following code to build a basic logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/angelika/Desktop/Shipt-DataAnalyst-TakeHome/InterviewData_Activity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5420 entries, 0 to 5419\n",
      "Data columns (total 7 columns):\n",
      "userid               5420 non-null object\n",
      "date                 5420 non-null object\n",
      "age                  5420 non-null int64\n",
      "gender               5420 non-null object\n",
      "metropolitan_area    5420 non-null object\n",
      "device_type          5420 non-null object\n",
      "active               5420 non-null int64\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 296.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>date</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>metropolitan_area</th>\n",
       "      <th>device_type</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e3a9ea937b3a</td>\n",
       "      <td>8/4/15</td>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4e3dd5154a08c</td>\n",
       "      <td>8/6/15</td>\n",
       "      <td>43</td>\n",
       "      <td>F</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e3df1ecd131a</td>\n",
       "      <td>8/6/15</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e4e77461b1e3</td>\n",
       "      <td>8/19/15</td>\n",
       "      <td>56</td>\n",
       "      <td>F</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4e4eb59b6de55</td>\n",
       "      <td>8/19/15</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userid     date  age gender metropolitan_area device_type  active\n",
       "0  4e3a9ea937b3a   8/4/15   30      F           Detroit      Tablet       1\n",
       "1  4e3dd5154a08c   8/6/15   43      F         Charlotte     Desktop       1\n",
       "2  4e3df1ecd131a   8/6/15   41      F             Tampa      Mobile       1\n",
       "3  4e4e77461b1e3  8/19/15   56      F         Nashville     Desktop       1\n",
       "4  4e4eb59b6de55  8/19/15   33      F           Detroit      Mobile       1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "dummy_genders = pd.get_dummies(df['gender'], prefix = 'gender')\n",
    "dummy_metro = pd.get_dummies(df['metropolitan_area'], prefix = 'metro_area')\n",
    "dummy_device = pd.get_dummies(df['device_type'], prefix = 'device')\n",
    "cols_to_keep = ['active', 'age']\n",
    "activity_data = df[cols_to_keep].join(dummy_genders.ix[:, 'gender_M':])\n",
    "activity_data = activity_data.join(dummy_metro.ix[:, 'metro_area_Birmingham':])\n",
    "activity_data = activity_data.join(dummy_device.ix[:, 'device_Mobile':])\n",
    "activity_data = sm.add_constant(activity_data, prepend=False)\n",
    "explanatory_cols = activity_data.columns[1:]\n",
    "full_logit_model = sm.GLM(activity_data['active'], activity_data[explanatory_cols], family=sm.families.Binomial())\n",
    "result = full_logit_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 active   No. Observations:                 5420\n",
      "Model:                            GLM   Df Residuals:                     5408\n",
      "Model Family:                Binomial   Df Model:                           11\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -3613.1\n",
      "Date:                Thu, 24 Sep 2020   Deviance:                       7226.3\n",
      "Time:                        13:01:33   Pearson chi2:                 5.38e+03\n",
      "No. Iterations:                    22   Covariance Type:             nonrobust\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "age                       0.0136      0.003      5.180      0.000       0.008       0.019\n",
      "gender_M                 -0.6103      0.083     -7.343      0.000      -0.773      -0.447\n",
      "metro_area_Birmingham    -0.0547      0.095     -0.576      0.564      -0.241       0.131\n",
      "metro_area_Charlotte     -1.8619      0.337     -5.529      0.000      -2.522      -1.202\n",
      "metro_area_Detroit       -0.0792      0.115     -0.689      0.491      -0.304       0.146\n",
      "metro_area_Houston       -0.4496      0.093     -4.850      0.000      -0.631      -0.268\n",
      "metro_area_Mobile        -1.7244      0.259     -6.655      0.000      -2.232      -1.217\n",
      "metro_area_Nashville     22.4506   1.35e+04      0.002      0.999   -2.64e+04    2.64e+04\n",
      "metro_area_Tampa          0.1370      0.104      1.312      0.189      -0.068       0.342\n",
      "device_Mobile            -1.5004      0.264     -5.685      0.000      -2.018      -0.983\n",
      "device_Tablet            -1.2342      0.269     -4.585      0.000      -1.762      -0.707\n",
      "const                     1.1553      0.290      3.991      0.000       0.588       1.723\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this model to the same data that the model was trained on and assess the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = activity_data[explanatory_cols].values  # explanatory values\n",
    "y = activity_data['active'].values          # target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of our model is 58.0%\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=20191016).fit(X, y)\n",
    "print('The accuracy of our model is %0.1f%%' % (clf.score(X, y)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question5\n",
    "Split the data into training and test samples,and build a model over the training data using the following Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = activity_data[1:4000]\n",
    "test_data = activity_data[4001:].copy()\n",
    "training_logit_model = sm.GLM(training_data['active'],\n",
    "training_data[explanatory_cols],\n",
    "family=sm.families.Binomial())\n",
    "training_result = training_logit_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the training data model’s accuracy on the test data. Why does the accuracy change so much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = test_data[explanatory_cols].values\n",
    "y1 = test_data['active'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of our model is 90.9%\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=20191016).fit(X1, y1)\n",
    "print('The accuracy of our model is %0.1f%%' % (clf.score(X1, y1)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to answer question about accuracy difference I need to explore and analyze data as well as measure classification performance metrics in details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = activity_data[1:4000]\n",
    "test_data = activity_data[4001:].copy()\n",
    "training_logit_model = sm.GLM(training_data['active'],\n",
    "training_data[explanatory_cols],\n",
    "family=sm.families.Binomial())\n",
    "training_result = training_logit_model.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 active   No. Observations:                 3999\n",
      "Model:                            GLM   Df Residuals:                     3987\n",
      "Model Family:                Binomial   Df Model:                           11\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2554.6\n",
      "Date:                Thu, 24 Sep 2020   Deviance:                       5109.3\n",
      "Time:                        13:01:33   Pearson chi2:                 3.97e+03\n",
      "No. Iterations:                    22   Covariance Type:             nonrobust\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "age                       0.0071      0.003      2.227      0.026       0.001       0.013\n",
      "gender_M                 -0.5802      0.097     -5.981      0.000      -0.770      -0.390\n",
      "metro_area_Birmingham    -0.1187      0.115     -1.037      0.300      -0.343       0.106\n",
      "metro_area_Charlotte     -1.7834      0.382     -4.663      0.000      -2.533      -1.034\n",
      "metro_area_Detroit       -0.1390      0.138     -1.007      0.314      -0.409       0.132\n",
      "metro_area_Houston       -0.4865      0.112     -4.358      0.000      -0.705      -0.268\n",
      "metro_area_Mobile        -1.7606      0.284     -6.202      0.000      -2.317      -1.204\n",
      "metro_area_Nashville     21.8608   1.33e+04      0.002      0.999    -2.6e+04     2.6e+04\n",
      "metro_area_Tampa          0.1892      0.127      1.484      0.138      -0.061       0.439\n",
      "device_Mobile            -1.5818      0.291     -5.428      0.000      -2.153      -1.011\n",
      "device_Tablet            -1.2830      0.298     -4.309      0.000      -1.867      -0.699\n",
      "const                     2.0245      0.327      6.187      0.000       1.383       2.666\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(training_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2501\n",
       "0    1500\n",
       "Name: active, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_data[:4001].active.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1290\n",
       "1     129\n",
       "Name: active, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_data[4001:].active.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like our data was heavily unbalanced for the test case. That could be a potential reason. In order to make sure let's explore confusion matrix as well as other measuring classification performance values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2790,    0],\n",
       "       [2630,    0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X)\n",
    "confusion_matrix(y, y_pred)\n",
    "# matrix outputs values in the following order:\n",
    "# TN FP\n",
    "# FN TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1290,    0],\n",
       "       [ 129,    0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = clf.predict(X1)\n",
    "confusion_matrix(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      1.00      0.68      2790\n",
      "          1       0.00      0.00      0.00      2630\n",
      "\n",
      "avg / total       0.26      0.51      0.35      5420\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95      1290\n",
      "          1       0.00      0.00      0.00       129\n",
      "\n",
      "avg / total       0.83      0.91      0.87      1419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y1, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bingo, it seems like the model cannot predict Positives values correctly. Since accuracy is literally a total number of predictions the model gets right. Or, in other words, a ratio of correctly predicted observation to the total observations, failing at predicting True and False Positives will heavily influence the model's accuracy. Moreover, there is a direct correlation between the number of activity == 1 values (Positives) and accuracy value, the larger the number of activity == 1 values in the data the lower the accuracy will be (in this particular case). \n",
    "In addition, other classification performance matrices such as precision and recall back up our observations - model does not do a good job at predicting positive values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In both cases our model completely fails at predicting true and false positive values (activity == 1). As a result, overall accuracy illustates that and highly connects to number of activity == 1 values. For example, in the test case, our data is unballanced (almoust all values are for activity == 0) as a result, model predicts correct values more often and accuracy goes higher. On the other hand, in the first case we have almoust even number of values (2501 for activity == 1 and 1500 for activity == 0). Therefore, our model is failing more often at predicitng Positives, and influences overall accuracy in a negative way. In aditiion, precision and recall values (evaluation metrices responsible for estimating how precise a model is in predicting positive labels) prove our conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question6\n",
    "This data comes from a subset of user data JSON blobs stored in our database.Parse out the values (stored in the “data_to_parse” column) into four separate columns. So for example, the four additional columns for the first entry would have values of “N”, “U”, “A7”, and “W”. You can use any functions/packages you want for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsing = pd.read_csv(\"/Users/angelika/Desktop/Shipt-DataAnalyst-TakeHome/InterviewData_Parsing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>data_to_parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54f3ad9a29ada</td>\n",
       "      <td>\"value\":\"N;U;A7;W\"}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54f69f2de6aec</td>\n",
       "      <td>\"value\":\"N;U;I6;W\"}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54f650f004474</td>\n",
       "      <td>\"value\":\"Y;U;A7;W\"}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54f52e8872227</td>\n",
       "      <td>\"value\":\"N;U;I1;W\"}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54f64d3075b72</td>\n",
       "      <td>\"value\":\"Y;U;A7;W\"}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userid         data_to_parse\n",
       "0  54f3ad9a29ada  \"value\":\"N;U;A7;W\"}]\n",
       "1  54f69f2de6aec  \"value\":\"N;U;I6;W\"}]\n",
       "2  54f650f004474  \"value\":\"Y;U;A7;W\"}]\n",
       "3  54f52e8872227  \"value\":\"N;U;I1;W\"}]\n",
       "4  54f64d3075b72  \"value\":\"Y;U;A7;W\"}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will parse data into two parts: \"value\": and string after that. Since I am interested only in the second part I will not save the first one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsing['temp'] = parsing['data_to_parse'].str.split(\":\").str[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will split data again into 4 different parts, using ; separator in order to distinguish split spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsing['A'] = parsing['temp'].str.split(\";\").str[0]\n",
    "parsing['A'] = parsing['A'].str.split('\"').str[1]\n",
    "parsing['B'] = parsing['temp'].str.split(\";\").str[1]\n",
    "parsing['C'] = parsing['temp'].str.split(\";\").str[2]\n",
    "parsing['Z'] = parsing['temp'].str.split(\";\").str[3]\n",
    "parsing['Z'] = parsing['Z'].str.split('\"').str[0]\n",
    "parsing = parsing.drop(columns = [\"temp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also created new columns for every split part and saved them to the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>data_to_parse</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54f3ad9a29ada</td>\n",
       "      <td>\"value\":\"N;U;A7;W\"}]</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>A7</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54f69f2de6aec</td>\n",
       "      <td>\"value\":\"N;U;I6;W\"}]</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>I6</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54f650f004474</td>\n",
       "      <td>\"value\":\"Y;U;A7;W\"}]</td>\n",
       "      <td>Y</td>\n",
       "      <td>U</td>\n",
       "      <td>A7</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54f52e8872227</td>\n",
       "      <td>\"value\":\"N;U;I1;W\"}]</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>I1</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54f64d3075b72</td>\n",
       "      <td>\"value\":\"Y;U;A7;W\"}]</td>\n",
       "      <td>Y</td>\n",
       "      <td>U</td>\n",
       "      <td>A7</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userid         data_to_parse  A  B   C  Z\n",
       "0  54f3ad9a29ada  \"value\":\"N;U;A7;W\"}]  N  U  A7  W\n",
       "1  54f69f2de6aec  \"value\":\"N;U;I6;W\"}]  N  U  I6  W\n",
       "2  54f650f004474  \"value\":\"Y;U;A7;W\"}]  Y  U  A7  W\n",
       "3  54f52e8872227  \"value\":\"N;U;I1;W\"}]  N  U  I1  W\n",
       "4  54f64d3075b72  \"value\":\"Y;U;A7;W\"}]  Y  U  A7  W"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, task is completed, data is parsed and saved to seprate columns as we wanted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition Question\n",
    "One of the ways we attract new members is through digital marketing campaigns (e.g., on Facebook). Assume that we know a little bit about potential users who see an ad for Shipt on Facebook – things like name and general metropolitan area, and then can measure the impressions on the ad, clicks to our landing page, and then conversions on our landing page. Our goal then is to drive more conversions on the landing page. What are some ways you might look at the already collected data (or some ways to enrich the existing data set) to try and make recommendations to the Marketing team for how to optimize their campaigns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we would need to identify relationships between information that we have and conversions on our landing page. This way we will be able to target and identify what areas are working out well and what are not. For example, is people in certain metropolitan area are bringing more conversions than in others? (We could push advertisement more in some specific areas). Do people who have positive impressions of the ad bring more conversions or not? (If no, then maybe advertisement does not clearly illustrate website purpose or vice versa). In addition, we can analyze landing page by itself. What are the places people are clicking on the page the most? What is scrolling activity of the page? (If many people scroll down some part we might need to improve it). How much time people spend on the page and how it influences conversion? What is the content of the page. Or more specifically, is the page content too complicated or on the contrary does not provide enough information? Finally, how clicks influence conversions? (maybe there are too many clicks and low conversions? This might indicate the people are getting confused or tired while deep diving into page’s content). On top of that, we know that the ad comes from Facebook. Therefore, we could potentially extract some additional information on users such as age, gender, occupation and on devices the website was accessed from (from latest we can identify whether or not website performance and visuals depend on the device and if yes then how). While we can perform some machine learning models with current data (Random Forest, Decision Tree, SVM, Logistic Regression etc.), larger amount of data and its diversity would allow us to improve them and apply new algorithms. This will allow us to deep dive into factors that can potentially increase / decrease members activity on the landing page. \n",
    "In colclusion there are several specific areas we could target in order to understand their influence on the convergence of the landing page:\n",
    "* metropolitan area\n",
    "* impression of the add\n",
    "* landing page components\n",
    "* landing page content\n",
    "* clicks\n",
    "* potential features we could bring in\n",
    "* perform machine learning models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
